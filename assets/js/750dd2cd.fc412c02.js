"use strict";(self.webpackChunkwarp_ai=self.webpackChunkwarp_ai||[]).push([[315],{3905:function(e,t,i){i.d(t,{Zo:function(){return c},kt:function(){return d}});var n=i(7294);function r(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function a(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,n)}return i}function o(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?a(Object(i),!0).forEach((function(t){r(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):a(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function s(e,t){if(null==e)return{};var i,n,r=function(e,t){if(null==e)return{};var i,n,r={},a=Object.keys(e);for(n=0;n<a.length;n++)i=a[n],t.indexOf(i)>=0||(r[i]=e[i]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)i=a[n],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(r[i]=e[i])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),i=t;return e&&(i="function"==typeof e?e(t):o(o({},t),e)),i},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var i=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=p(i),d=r,f=m["".concat(l,".").concat(d)]||m[d]||u[d]||a;return i?n.createElement(f,o(o({ref:t},c),{},{components:i})):n.createElement(f,o({ref:t},c))}));function d(e,t){var i=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=i.length,o=new Array(a);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<a;p++)o[p]=i[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,i)}m.displayName="MDXCreateElement"},5871:function(e,t,i){i.r(t),i.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return d},frontMatter:function(){return s},metadata:function(){return p},toc:function(){return u}});var n=i(7462),r=i(3366),a=(i(7294),i(3905)),o=["components"],s={sidebar_position:2},l="Image Classification Web App",p={unversionedId:"Building-AI-App/classifier",id:"Building-AI-App/classifier",title:"Image Classification Web App",description:"Classification Model",source:"@site/docs/Building-AI-App/classifier.md",sourceDirName:"Building-AI-App",slug:"/Building-AI-App/classifier",permalink:"/warp-ai-vision/docs/Building-AI-App/classifier",draft:!1,editUrl:"https://github.com/CMKL-University/warp-ai-vision/tree/main/warp-ai/docs/Building-AI-App/classifier.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Building Apps with StreamLit",permalink:"/warp-ai-vision/docs/Building-AI-App/streamlit"}},c={},u=[{value:"Classification Model",id:"classification-model",level:2},{value:"Web Application",id:"web-application",level:2}],m={toc:u};function d(e){var t=e.components,i=(0,r.Z)(e,o);return(0,a.kt)("wrapper",(0,n.Z)({},m,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"image-classification-web-app"},"Image Classification Web App"),(0,a.kt)("h2",{id:"classification-model"},"Classification Model"),(0,a.kt)("p",null,"We will utilize the ResNet-101 classifier available via TorchVision (more models are available from ",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/hub/"},"PyTorch Hub"),'). ResNet-101 is a 101-layer deep learning network proposed in "',(0,a.kt)("a",{parentName:"p",href:"https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition"},"Deep Residual Learning for Image Recognition"),'". ResNet is one of the most popular architecture for classifiers with over 20,000 citations. The model introduced residual blocks where an identity shortcut connection that skips layer, solving vanishing gradient problem in very deep neural networks.'),(0,a.kt)("p",null,"The following code uses pretrained ResNet-101 model to classify the image into one of the thousand categories available from ",(0,a.kt)("a",{parentName:"p",href:"https://www.image-net.org/download.php"},"ImageNet")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="classifier.py"',title:'"classifier.py"'},'from torchvision import models, transforms\nimport torch\nfrom PIL import Image\n\ndef predict(image_path):\n    # Step 1: Initialize model with the best available weights\n    weights = models.ResNet101_Weights.DEFAULT\n    model = models.resnet101(weights=weights)\n    model.eval()\n\n    # Step 2: Initialize the inference transforms\n    preprocess = weights.transforms()\n\n    # Step 3: Apply inference preprocessing transforms\n    img = Image.open(image_path)\n    batch = preprocess(img).unsqueeze(0)\n\n    # Step 4: Use the model and print the predicted category\n    out = model(batch)\n    prob = out.squeeze(0).softmax(0)*100\n    _, indices = torch.sort(out, descending=True)\n    classes = weights.meta["categories"]\n    return [(classes[idx], prob[idx].item()) for idx in indices[0][:5]]\n')),(0,a.kt)("h2",{id:"web-application"},"Web Application"),(0,a.kt)("p",null,"The web application can be built using basic Python script. The following example include file uploader widget which allows user to upload image to be classfied by the model."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="app.py"',title:'"app.py"'},'import streamlit as st\nfrom PIL import Image\nfrom classifier import predict\n\n# Initialize app page and file uploader widget\nst.title("ResNet Image Classifier")\nfile_up = st.file_uploader("Upload an image", type="jpg")\n\nif file_up is not None:\n    # After a user uploaded the image, open and display the image\n    image = Image.open(file_up)\n    st.image(image, caption=\'Uploaded Image.\', use_column_width=True)\n\n    # Call the prediction code to classify the image\n    st.write("Thinking...")\n    labels = predict(file_up)\n\n    # Print out the top 5 prediction labels with scores\n    for i in labels:\n        st.write("Prediction \u2192", i[0], ",   Score: ", i[1], "%")\n')),(0,a.kt)("p",null,"You can use Streamlit to launch the app. Try uploading a jpg image to see the classfication result."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"streamlit run app.py\n")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Acknowledgement :")," The content of this document has been adapted from these original websites."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://wiki.hasty.ai/model-architectures/resnet"},"Hasty vision AI Wiki: ResNet")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://pytorch.org/vision/main/models.html"},"Torchvision models and pre-trained weights")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/create-an-image-classification-web-app-using-pytorch-and-streamlit-f043ddf00c24"},"Create an Image Classification Web App using PyTorch and Streamlit"))))}d.isMDXComponent=!0}}]);