"use strict";(self.webpackChunkwarp_ai=self.webpackChunkwarp_ai||[]).push([[788],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=d(n),m=r,h=u["".concat(l,".").concat(m)]||u[m]||c[m]||o;return n?a.createElement(h,i(i({ref:t},p),{},{components:n})):a.createElement(h,i({ref:t},p))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var d=2;d<o;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},1943:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return s},metadata:function(){return d},toc:function(){return c}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=["components"],s={sidebar_position:3},l="Classification and Neural Network using PyTorch",d={unversionedId:"Introduction-to-Neural-Network/quickstart",id:"Introduction-to-Neural-Network/quickstart",title:"Classification and Neural Network using PyTorch",description:"Working with data",source:"@site/docs/Introduction-to-Neural-Network/quickstart.md",sourceDirName:"Introduction-to-Neural-Network",slug:"/Introduction-to-Neural-Network/quickstart",permalink:"/warp-ai-vision/docs/Introduction-to-Neural-Network/quickstart",draft:!1,editUrl:"https://github.com/CMKL-University/warp-ai-vision/tree/main/warp-ai/docs/Introduction-to-Neural-Network/quickstart.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"PyTorch with CUDA device",permalink:"/warp-ai-vision/docs/Introduction-to-Neural-Network/cuda"},next:{title:"Convolutional Neural Network",permalink:"/warp-ai-vision/docs/CNN-and-Object-Detection/convNet"}},p={},c=[{value:"Working with data",id:"working-with-data",level:2},{value:"Creating Models",id:"creating-models",level:2},{value:"<strong>Optimizing the Model Parameters</strong>",id:"optimizing-the-model-parameters",level:2},{value:"<strong>Saving Models</strong>",id:"saving-models",level:2},{value:"<strong>Loading Models</strong>",id:"loading-models",level:2}],u={toc:c};function m(e){var t=e.components,n=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"classification-and-neural-network-using-pytorch"},"Classification and Neural Network using PyTorch"),(0,o.kt)("h2",{id:"working-with-data"},"Working with data"),(0,o.kt)("p",null,"PyTorch has two primitives to work with data: ",(0,o.kt)("inlineCode",{parentName:"p"},"torch.utils.data.DataLoader")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"torch.utils.data.Dataset"),". ",(0,o.kt)("inlineCode",{parentName:"p"},"Dataset"),"\xa0stores the samples and their corresponding labels, and\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"DataLoader"),"\xa0wraps an iterable around the\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"Dataset"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n")),(0,o.kt)("p",null,"Dataset: The\xa0",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("inlineCode",{parentName:"strong"},"datasets")),"\xa0retrieves our dataset\u2019s features and labels one sample at a time."),(0,o.kt)("p",null,"Dataloader:  ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("inlineCode",{parentName:"strong"},"DataLoader")),"\xa0is an iterable that abstracts this complexity for us in an easy API."),(0,o.kt)("p",null,"PyTorch offers domain-specific libraries such as\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/text/stable/index.html"},"TorchText"),",\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/vision/stable/index.html"},"TorchVision"),", and\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/audio/stable/index.html"},"TorchAudio"),", all of which include datasets. For section, we will be using a TorchVision\u2019s FashionMNIST dataset."),(0,o.kt)("p",null,"To import the FashionMNIST dataset from TorchVision "),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"root"),"\xa0is the path where the train/test data is stored,"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"train"),"\xa0specifies training or test dataset,"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"download=True"),"\xa0downloads the data from the internet if it\u2019s not available at\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"root"),"."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"transform"),"\xa0and\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"target_transform"),"\xa0specify the feature and label transformations"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Download training data from open datasets. \n# this will load the dataset to \'data\', \ntraining_data = datasets.FashionMNIST(\n    root="data", \n    train=True, \n    download=True, \n    transform=ToTensor(),\n)\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root="data",\n    train=False, # test data should set train=False\n    download=True,\n    transform=ToTensor(),\n)\n')),(0,o.kt)("p",null,"DataLoader wraps an iterable over our training and testing dataset and returns it as a batch of 64 features and labels. We can test our dataloader by iterate through ",(0,o.kt)("inlineCode",{parentName:"p"},"test_dataloader"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'batch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f"Shape of X [N, C, H, W]: {X.shape}")\n    print(f"Shape of y: {y.shape} {y.dtype}")\n    break\n')),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Read more about\xa0",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"},"loading data in PyTorch"),"."))),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"creating-models"},"Creating Models"),(0,o.kt)("p",null,"To define a neural network in PyTorch, we create a class that inherits from\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/generated/torch.nn.Module.html"},"nn.Module"),". We define the layers of the network in the\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"__init__"),"\xa0function and specify how data will pass through the network in the\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"forward"),"\xa0function. To accelerate operations in the neural network, we move it to the GPU if available."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Get cpu or gpu device for training.\ndevice = "cuda" if torch.cuda.is_available() else "cpu"\nprint(f"Using {device} device")\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n')),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Read more about\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"},"building neural networks in PyTorch"),".")),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"optimizing-the-model-parameters"},(0,o.kt)("strong",{parentName:"h2"},"Optimizing the Model Parameters")),(0,o.kt)("p",null,"To train a model, we need a\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/nn.html#loss-functions"},"loss function"),"\xa0and an\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/stable/optim.html"},"optimizer"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # lr is Learning Rate\n")),(0,o.kt)("p",null,"In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model\u2019s parameters."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")\n')),(0,o.kt)("p",null,"We also check the model\u2019s performance against the test dataset to ensure it is learning."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n")\n')),(0,o.kt)("p",null,"The training process is conducted over several iterations (",(0,o.kt)("em",{parentName:"p"},"epochs"),"). During each epoch, the model learns parameters to make better predictions. We print the model\u2019s accuracy and loss at each epoch; we\u2019d like to see the accuracy increase and the loss decrease with every epoch."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'epochs = 5\nfor t in range(epochs):\n    print(f"Epoch {t+1}\\n-------------------------------")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint("Done!")\n')),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Read more about\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"},"Training your model"),".")),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"saving-models"},(0,o.kt)("strong",{parentName:"h2"},"Saving Models")),(0,o.kt)("p",null,"A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'torch.save(model.state_dict(), "model.pth")\nprint("Saved PyTorch Model State to model.pth")\n')),(0,o.kt)("h2",{id:"loading-models"},(0,o.kt)("strong",{parentName:"h2"},"Loading Models")),(0,o.kt)("p",null,"The process for loading a model includes re-creating the model structure and loading the state dictionary into it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'model = NeuralNetwork()\nmodel.load_state_dict(torch.load("model.pth"))\n')),(0,o.kt)("p",null,"This model can now be used to make predictions."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'classes = [\n    "T-shirt/top",\n    "Trouser",\n    "Pullover",\n    "Dress",\n    "Coat",\n    "Sandal",\n    "Shirt",\n    "Sneaker",\n    "Bag",\n    "Ankle boot",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f\'Predicted: "{predicted}", Actual: "{actual}"\')\n')),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Read more about\xa0",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html"},"Saving & Loading your model"),".")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Acknowledgement"),": The content of this document has been adapted from the original ",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"},"PyTorch quickstart"),"."))}m.isMDXComponent=!0}}]);