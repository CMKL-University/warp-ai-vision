"use strict";(self.webpackChunkwarp_ai=self.webpackChunkwarp_ai||[]).push([[517],{3905:function(e,n,t){t.d(n,{Zo:function(){return s},kt:function(){return h}});var r=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var p=r.createContext({}),u=function(e){var n=r.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},s=function(e){var n=u(e.components);return r.createElement(p.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},m=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),m=u(t),h=a,g=m["".concat(p,".").concat(h)]||m[h]||c[h]||o;return t?r.createElement(g,i(i({ref:n},s),{},{components:t})):r.createElement(g,i({ref:n},s))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=m;var l={};for(var p in n)hasOwnProperty.call(n,p)&&(l[p]=n[p]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var u=2;u<o;u++)i[u]=t[u];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}m.displayName="MDXCreateElement"},6952:function(e,n,t){t.r(n),t.d(n,{assets:function(){return s},contentTitle:function(){return p},default:function(){return h},frontMatter:function(){return l},metadata:function(){return u},toc:function(){return c}});var r=t(7462),a=t(3366),o=(t(7294),t(3905)),i=["components"],l={},p="Hough Line Transform in OpenCV",u={unversionedId:"lab-book/opencv",id:"lab-book/opencv",title:"Hough Line Transform in OpenCV",description:"Introduction to Hough Transform",source:"@site/docs/lab-book/opencv.md",sourceDirName:"lab-book",slug:"/lab-book/opencv",permalink:"/warp-ai-vision/docs/lab-book/opencv",draft:!1,editUrl:"https://github.com/CMKL-University/warp-ai-vision/tree/main/warp-ai/docs/lab-book/opencv.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"PyTorch with CUDA device",permalink:"/warp-ai-vision/docs/lab-book/cuda"},next:{title:"Deep Residual Network (ResNet)",permalink:"/warp-ai-vision/docs/lab-book/resnet"}},s={},c=[{value:"Introduction to Hough Transform",id:"introduction-to-hough-transform",level:2},{value:"<strong>Probabilistic Hough Transform</strong>",id:"probabilistic-hough-transform",level:2}],m={toc:c};function h(e){var n=e.components,t=(0,a.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"hough-line-transform-in-opencv"},"Hough Line Transform in OpenCV"),(0,o.kt)("h2",{id:"introduction-to-hough-transform"},"Introduction to Hough Transform"),(0,o.kt)("p",null,"The Hough Transform is a popular technique to detect any shape, if you can represent that shape in a mathematical form. It can detect the shape even if it is broken or distorted a little bit. We will see how it works for a line using OpenCV. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import cv2 as cv\nimport numpy as np\n")),(0,o.kt)("p",null,"We read the sudoku.png that store in our data directory and convert it into gray scale. Next, we use ",(0,o.kt)("inlineCode",{parentName:"p"},"cv.Canny()")," to detect the edge of the image."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"img = cv.imread('../data/sudoku.png')\ngray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\nedges = cv.Canny(gray,50,150,apertureSize = 3)\n")),(0,o.kt)("p",null,"We use ",(0,o.kt)("inlineCode",{parentName:"p"},"cv.HoughLines()")," function to perform Hough Transform. It returns array of line parametees (rho, theta) values."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"edges")," : binary edge detected image input"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"1")," : rho value"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"np.pi/180")," : theta"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"200")," : threshold")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"lines = cv.HoughLines(edges,1,np.pi/180,200)\n")),(0,o.kt)("p",null,"Iterate through each (rho, theta) order paired and convert it back to the points on cartesian plane and draw the intersect line between two point on the input image. Finally, we save the output image to our preferred location."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"for line in lines:\n    rho,theta = line[0]\n    a = np.cos(theta)\n    b = np.sin(theta)\n    x0 = a*rho\n    y0 = b*rho\n    x1 = int(x0 + 1000*(-b))\n    y1 = int(y0 + 1000*(a))\n    x2 = int(x0 - 1000*(-b))\n    y2 = int(y0 - 1000*(a))\n    cv.line(img,(x1,y1),(x2,y2),(0,0,255),2)\ncv.imwrite('../output/houghlines3.jpg',img)\n")),(0,o.kt)("hr",null),(0,o.kt)("h2",{id:"probabilistic-hough-transform"},(0,o.kt)("strong",{parentName:"h2"},"Probabilistic Hough Transform")),(0,o.kt)("p",null,"Probabilistic Hough Transform is an optimization of the Hough Transform we saw, it takes only a random subset of points which is sufficient for line detection."),(0,o.kt)("p",null,"In openCV we can perform the Probabilistic Hough Transform by using ",(0,o.kt)("inlineCode",{parentName:"p"},"cv.HoughLinesP()")," function."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import cv2 as cv\nimport numpy as np\nimg = cv.imread('../data/sudoku.png')\ngray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\nedges = cv.Canny(gray,50,150,apertureSize = 3)\n")),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"cv.HoughLinesP()")," parameters if similar to ",(0,o.kt)("inlineCode",{parentName:"p"},"cv.HoughLines()")," except it takes two new arguments."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"minLineLength"),"\xa0- Minimum length of line. Line segments shorter than this are rejected"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"maxLineGap")," - Maximum allowed gap between line segments to treat them as a single line")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"lines = cv.HoughLinesP(edges,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"cv.HoughLinesP()")," function returns the line's two endpoints, whereas the ",(0,o.kt)("inlineCode",{parentName:"p"},"cv.HoughLines()")," function returns the rho, theta parameters. Then we iterate through each pair of endpoints and draw the line between two endpoints on the input image. Finally, we save our output image as a file."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"for line in lines:\n    x1,y1,x2,y2 = line[0]\n    cv.line(img,(x1,y1),(x2,y2),(0,255,0),2)\ncv.imwrite('../output/houghlines5.jpg',img)\n")))}h.isMDXComponent=!0}}]);